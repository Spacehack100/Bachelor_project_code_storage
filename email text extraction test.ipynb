{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b190d3c",
   "metadata": {},
   "source": [
    "# Import necassary libraries and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5694f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jensk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jensk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from email import policy\n",
    "from email.parser import BytesParser\n",
    "import os\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import nltk.corpus\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem.snowball import DutchStemmer\n",
    "import spacy\n",
    "import dutch_words\n",
    "from imap_tools import MailBox, AND\n",
    "lemmaModel = spacy.load('nl_core_news_lg', disable = ['parser','ner'])\n",
    "\n",
    "# Checked wordlist\n",
    "#dutchCorpusFile = open(Path(os.getcwd() + '/opentaal-wordlist-master/elements/basiswoorden-gekeurd.txt'))\n",
    "\n",
    "# Unchecked wordlist\n",
    "dutchCorpusFile = open(Path(os.getcwd() + '/opentaal-wordlist-master/wordlist.txt'))\n",
    "dutchCorpusData = dutchCorpusFile.read()\n",
    "dutchCorpus = dutchCorpusData.replace('\\n', '.').split(\".\")\n",
    "dutchCorpusFile.close()\n",
    "\n",
    "# set column width to maximum for better visibility of data\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5740c6a6",
   "metadata": {},
   "source": [
    "# Define cleanup/pre-processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7689aefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that extracts text from HTML tags\n",
    "def ExtractHTML(contentInput):\n",
    "    contentOutput = BeautifulSoup(contentInput).get_text()\n",
    "    return contentOutput\n",
    "\n",
    "# Function that removes escape characters (for example newlines)\n",
    "def RemoveEscapeCharacters(contentInput):\n",
    "    escapes = ''.join([chr(char) for char in range(1, 32)])\n",
    "    #translator = str.maketrans(escapes, ' ')\n",
    "    #content = content.translate(translator)\n",
    "    contentOutput = re.sub(r'[' + escapes + r']',' ', contentInput)\n",
    "    return contentOutput\n",
    "\n",
    "# Function that removes URL's from mails (maybe not necassary)\n",
    "def RemoveURLs(contentInput):\n",
    "    contentOutput = re.sub(r'http\\S+', ' ', contentInput)\n",
    "    return contentOutput\n",
    "    \n",
    "# Function that removes extra whitespaces\n",
    "def RemoveExcessWhitespaces(contentInput):\n",
    "    contentOutput = re.sub(' {2,}', ' ', contentInput)\n",
    "    return contentOutput\n",
    "\n",
    "# Function for removing excess non-alphanumeric characters (and punctuation)\n",
    "def RemoveNonAlphanumeric(contentInput, removePunctuation = False):\n",
    "    # with punctuation\n",
    "    if removePunctuation == True:\n",
    "        contentOutput = re.sub(r'[^A-Za-z0-9 ]+', ' ',contentInput)\n",
    "        \n",
    "    # without punctuation\n",
    "    else:\n",
    "        contentOutput = re.sub(r'[^A-Za-z0-9 ,?.:;!_-]+', '',contentInput)\n",
    "        contentOutput = re.sub(r'([,?.:;!_-]\\s*){2,}','',contentOutput)\n",
    "        \n",
    "    return contentOutput\n",
    "\n",
    "# Function for additional filtering related to privacy\n",
    "def PrivacyFiltering(contentInput):\n",
    "    contentOutput = re.sub(r'(BIC:) [A-Z]*',' ',contentInput)\n",
    "    contentOutput = re.sub(r'\\w*\\d\\w*', ' ', contentOutput).strip()\n",
    "    return contentOutput\n",
    "\n",
    "# function for text to lower case\n",
    "def toLowerCase(contentInput):\n",
    "    contentOutput = contentInput.lower()\n",
    "    return contentOutput\n",
    "\n",
    "# Stopwords removal function\n",
    "def StopwordRemoval(contentInput, languageCode):\n",
    "    stop = stopwords.words(languageCode)\n",
    "    contentOutput =  \" \".join([word for word in contentInput.split() if word not in (stop)])\n",
    "    return contentOutput\n",
    "\n",
    "# Stemming function\n",
    "def Stemmer(contentInput):\n",
    "    tokenizedWords = word_tokenize(contentInput, language='dutch')\n",
    "    stemmedContent = []\n",
    "    stemmer = DutchStemmer()\n",
    "    for word in tokenizedWords:\n",
    "        stemmedContent.append(stemmer.stem(word))\n",
    "        stemmedContent.append(\" \")\n",
    "    return \"\".join(stemmedContent)\n",
    "\n",
    "# Lemmatization function\n",
    "def Lemmatizer(contentInput):\n",
    "    document = lemmaModel(contentInput)\n",
    "    return \" \".join([token.lemma_ for token in document])\n",
    "\n",
    "# Function to remove words not in dictionary\n",
    "def RemoveNonDictionaryWords(contentInput):\n",
    "        contentOutput =  \" \".join([word for word in contentInput.split() if word in (dutchCorpus)])\n",
    "        return contentOutput"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "306df0ca",
   "metadata": {},
   "source": [
    "# Extract content from the emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9f89f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kerseje\\Bachelerproef jupyter notebooks\\BrainjarMails\n",
      "Counter: 80/1855\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kerseje\\AppData\\Local\\miniconda3\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total character count: 1851465\n"
     ]
    }
   ],
   "source": [
    "# define and print path to .eml files (emails)\n",
    "pathString = os.getcwd() + 'path to email files'\n",
    "path = Path(pathString)\n",
    "pathLength = len(pathString)\n",
    "print(path)\n",
    "\n",
    "# grab every file with the extension .eml\n",
    "email_files = list(path.glob('*.eml'))\n",
    "\n",
    "# create lists for the names and content of the emails + filecounter\n",
    "names = []\n",
    "contents = []\n",
    "counter = 1\n",
    "fileCount = len(email_files)\n",
    "totalCharacterCount = 0\n",
    "\n",
    "# loop over all found files\n",
    "for email in email_files:\n",
    "    \n",
    "    #open each file in read bytes mode\n",
    "    with open(email,'rb') as filepointer:\n",
    "        \n",
    "        # name is original filename minus the path and extension\n",
    "        name = filepointer.name[pathLength:-4]\n",
    "        \n",
    "        # Parse data from email to message object\n",
    "        message = BytesParser(policy=policy.default).parse(filepointer)\n",
    "        \n",
    "    # pass the plain text from the body of the email to a string variable. If no plain text is availible, \n",
    "    # just pass everything in the body\n",
    "    try:\n",
    "        content = message.get_body(preferencelist=('plain')).get_content()\n",
    "    except:\n",
    "        content = message.get_body().get_content()\n",
    "    \n",
    "    # Extract text from any HTML that is present.\n",
    "    content = ExtractHTML(content)\n",
    "    \n",
    "    # Remove escape characters (for example newlines)\n",
    "    content = RemoveEscapeCharacters(content)\n",
    "    \n",
    "    # Remove any non-ascii characters\n",
    "    # content = content.encode('ascii', errors='ignore').decode()\n",
    "    \n",
    "    # Remove URL's from mails (maybe not necassary)\n",
    "    content = RemoveURLs(content)  \n",
    "    \n",
    "    # Additional filtering for privacy\n",
    "    content = PrivacyFiltering(content)\n",
    "    \n",
    "    # Remove non-alphanumeric characters\n",
    "    content = RemoveNonAlphanumeric(content)\n",
    "    \n",
    "    # remaining text to lower case\n",
    "    #content = toLowerCase(content)\n",
    "    \n",
    "    # Get amount of characters in all text\n",
    "    totalCharacterCount += len(content)\n",
    "     \n",
    "    # remove stopwords\n",
    "    #content = StopwordRemoval(content, 'dutch')\n",
    "    \n",
    "    # Stemming or lemmatization\n",
    "    #content = Stemmer(content)\n",
    "    #content = Lemmatizer(content)\n",
    "    \n",
    "    # remove words that are not in a dictionary (dutch in this case)\n",
    "    #content = RemoveNonDictionaryWords(content)\n",
    "    \n",
    "    # Remove extra whitespaces\n",
    "    content = RemoveExcessWhitespaces(content)\n",
    "    \n",
    "    # add name and content of current email to their respective lists\n",
    "    names.append(name)\n",
    "    contents.append(content)\n",
    "    \n",
    "    #close the current file\n",
    "    filepointer.close()\n",
    "    \n",
    "    # filecounter\n",
    "    print(\"Counter: \" + str(counter) + '/' + str(fileCount), end=\"\\r\")\n",
    "    counter += 1\n",
    "    \n",
    "print('Total character count: ' + str(totalCharacterCount))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "67aaf9ca",
   "metadata": {},
   "source": [
    "### Turn lists into dataframe for easy exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79a49587",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNames = pd.DataFrame([names, contents]).T\n",
    "dfNames.columns = ['names', 'contents']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "741da143",
   "metadata": {},
   "source": [
    "### Set class index based on title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b3bd004",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNames['classIndex'] = 0\n",
    "dfNames['classIndex'] = np.where(dfNames['names'].str.contains('facturen'), 1, dfNames['classIndex'])\n",
    "dfNames['classIndex'] = np.where(dfNames['names'].str.contains('aanmaningen'), 2, dfNames['classIndex'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "464e5d8f",
   "metadata": {},
   "source": [
    "Class list:\n",
    "- 0 = Other\n",
    "- 1 = invoice\n",
    "- 2 = Payement reminder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "95428035",
   "metadata": {},
   "source": [
    "### Drop columns wich contain Nan/Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "533b85f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(dfNames.isna().sum().sum())\n",
    "dfNames = dfNames.dropna()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8fc43b9b",
   "metadata": {},
   "source": [
    "### Display top 20 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86785a01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfNames.head(20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c6089602",
   "metadata": {},
   "source": [
    "### Make different dataframe for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0fd7c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetSentiment = dfNames.drop(dfNames[dfNames['classIndex'] == 0].index,axis=0)\n",
    "datasetSentiment.loc[datasetSentiment['classIndex'] == 1, 'classIndex'] = 0\n",
    "datasetSentiment.loc[datasetSentiment['classIndex'] == 2, 'classIndex'] = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6373910f",
   "metadata": {},
   "source": [
    "### Save dataframe to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2939c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNames.to_csv('test_extraction_emails.csv')\n",
    "datasetSentiment.to_csv('sentiment_exctraction_emails.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1b599d85",
   "metadata": {},
   "source": [
    "# Same operations on mailbox e-mails\n",
    "(see 'reading e-mails from inbox.ipynb' for reading script)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72fc1e13",
   "metadata": {},
   "source": [
    "### Password function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc5ae791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetPasswordFromFile(filePath):\n",
    "    f = open(filePath,\"r\")\n",
    "    password = f.read()\n",
    "    f.close()\n",
    "    return password"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34b92e9b",
   "metadata": {},
   "source": [
    "### Reading script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95211280",
   "metadata": {},
   "outputs": [],
   "source": [
    "mb = MailBox('<mailbox>').login('<email adress>',GetPasswordFromFile(os.getcwd() + '<password file>'))\n",
    "messages = mb.fetch(criteria=AND(seen=False), mark_seen=False, bulk=True)\n",
    "\n",
    "contents = []\n",
    "for msg in messages:\n",
    "    \n",
    "    content = msg.text\n",
    "    \n",
    "    content = ExtractHTML(content)\n",
    "    content = RemoveEscapeCharacters(content)\n",
    "    content = RemoveURLs(content)\n",
    "    content = PrivacyFiltering(content)\n",
    "    content = RemoveNonAlphanumeric(content)\n",
    "    content = RemoveExcessWhitespaces(content)\n",
    "    \n",
    "    contents.append(content)\n",
    "    \n",
    "contentsDf = pd.DataFrame(contents, columns=['contents'])\n",
    "contentsDf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b259c9d2",
   "metadata": {},
   "source": [
    "### Save to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3be6281",
   "metadata": {},
   "outputs": [],
   "source": [
    "contentsDf.to_csv('inbox_emails.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b75b8e90",
   "metadata": {},
   "source": [
    "# Clean second dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dcaf41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CleanNewMails(mailSet):\n",
    "    contents = []\n",
    "    counter = 1\n",
    "    fileCount = len(mailSet)\n",
    "    totalCharacterCount = 0\n",
    "    \n",
    "    for email in mailSet:\n",
    "        with open(email,'rb') as filepointer:\n",
    "            message = BytesParser(policy=policy.default).parse(filepointer)\n",
    "        \n",
    "        try:\n",
    "            content = message.get_body(preferencelist=('plain')).get_content()\n",
    "        except:\n",
    "            content = message.get_body().get_content()\n",
    "        \n",
    "        content = ExtractHTML(content)\n",
    "    \n",
    "        content = RemoveEscapeCharacters(content)\n",
    "    \n",
    "        content = RemoveURLs(content)  \n",
    "    \n",
    "        content = PrivacyFiltering(content)\n",
    "    \n",
    "        content = RemoveNonAlphanumeric(content)\n",
    "        \n",
    "        totalCharacterCount += len(content)\n",
    "\n",
    "        content = RemoveExcessWhitespaces(content)\n",
    "        \n",
    "        content = toLowerCase(content)\n",
    "    \n",
    "        contents.append(content)\n",
    "    \n",
    "        filepointer.close()\n",
    "    \n",
    "        print(\"Counter: \" + str(counter) + '/' + str(fileCount), end=\"\\r\")\n",
    "        counter += 1\n",
    "    \n",
    "    print('Total character count: ' + str(totalCharacterCount))\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5aaf07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total character count: 7256554\n",
      "Total character count: 108205\n",
      "Total character count: 8193367\n",
      "Total character count: 694097\n",
      "Total character count: 332180\n"
     ]
    }
   ],
   "source": [
    "primaryPathString = os.getcwd() + 'path to email files'\n",
    "\n",
    "mailsAndere = list(Path(primaryPathString + '//Andere').glob('*.eml'))\n",
    "mailsCN = list(Path(primaryPathString + '//CN').glob('*.eml'))\n",
    "mailsOrders = list(Path(primaryPathString + '//Orders').glob('*.eml'))\n",
    "mailsRappels = list(Path(primaryPathString + '//Rappels').glob('*.eml'))\n",
    "mailsTechnoCargo = list(Path(primaryPathString + '//TechnoCargo').glob('*.eml'))\n",
    "\n",
    "mailsAndereClean = pd.DataFrame(CleanNewMails(mailsAndere), columns=['contents'])\n",
    "mailsCNClean = pd.DataFrame(CleanNewMails(mailsCN), columns=['contents'])\n",
    "mailsOrdersClean = pd.DataFrame(CleanNewMails(mailsOrders), columns=['contents'])\n",
    "mailsRappelsClean = pd.DataFrame(CleanNewMails(mailsRappels), columns=['contents'])\n",
    "mailsTechnoCargoClean = pd.DataFrame(CleanNewMails(mailsTechnoCargo), columns=['contents'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8d0d1ec3",
   "metadata": {},
   "source": [
    "### Save to csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9d01a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "savePath = 'path to save files'\n",
    "mailsAndereClean.to_csv(savePath + '\\Andere.csv')\n",
    "mailsCNClean.to_csv(savePath + '\\CN.csv')\n",
    "mailsOrdersClean.to_csv(savePath + '\\Orders.csv')\n",
    "mailsRappelsClean.to_csv(savePath + '\\Rappels.csv')\n",
    "mailsTechnoCargoClean.to_csv(savePath + '\\TechnoCargo.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3e2c26c",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "E-mails need a lot of cleaning to extract just the text and leave metacharacters (such as HTML or escape characters) out of the processed results. Beyond that we need more specific preprocessing steps, determined by the model that it will feed through. Unsupervised models will need stopword removal and lemmitazation/stemming to achieve higher performance, while transfer learning models like BERT will be hurt by these preprocessing steps."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8728ba18",
   "metadata": {},
   "source": [
    "#### Sources:\n",
    "- https://stackoverflow.com/questions/8115261/how-to-remove-all-the-escape-sequences-from-a-list-of-strings\n",
    "- https://enjoylifescience.com/2020/11/05/analyzing-emails-in-python/\n",
    "- https://stackoverflow.com/questions/11331982/how-to-remove-any-url-within-a-string-in-python\n",
    "- https://towardsdatascience.com/remove-personal-information-from-text-with-python-232cb69cf074\n",
    "- https://monkeylearn.com/blog/text-cleaning/#:~:text=Text%20cleaning%20can%20be%20performed,words%20to%20their%20root%20form.&text=You'd%20need%20to%20perform,Removing%20Stopwords\n",
    "- https://www.datacamp.com/tutorial/stemming-lemmatization-python\n",
    "- https://www.projectpro.io/recipes/use-spacy-lemmatizer\n",
    "- https://pypi.org/project/dutch-words/ (Original dictionary, replaced by Opentaal wordlist)\n",
    "- https://github.com/OpenTaal/opentaal-wordlist"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ecda76c1",
   "metadata": {},
   "source": [
    "# License"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec7b40b2",
   "metadata": {},
   "source": [
    "OpenTaal wordlist: Hagen, H., Brouwer, S., Baars, R., Roeckx, K., Maryns, H., Waalboer, J., & Knubben, B. (2017, Februari 16). opentaal-wordlist. Opgehaald van Github: https://github.com/OpenTaal/opentaal-wordlist"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
